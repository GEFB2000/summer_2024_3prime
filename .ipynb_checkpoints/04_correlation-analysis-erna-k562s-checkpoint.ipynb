{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3db336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['R_HOME'] = '/Users/geba9152/miniconda3/envs/rpy2_env/lib/R'\n",
    "import rpy2.rinterface\n",
    "\n",
    "# loads ipython extension\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ebbcc",
   "metadata": {},
   "source": [
    "06/03/2024\n",
    "\n",
    "I am performing a preliminary analysis for my F31 grant. Essentially I want to identify...\n",
    "\n",
    "Paper for validated gene-enhancer pairs: `Nasser, Joseph. et al. Nature 2021; 4, 408`\n",
    "\n",
    "1. The number of eRNAs present in run-on regions\n",
    "2. Distance from PAS to nearest eRNA contained within run-on region\n",
    "3. Correlation analysis with mT taken into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "186ace28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"K562\"                        \"NCCIT\"                      \n",
      " [3] \"PrimaryHepatocytes\"          \"BJAB_anti-IgM_anti-CD40_4hr\"\n",
      " [5] \"BJAB\"                        \"Jurkat_anti-CD3_PMA_4hr\"    \n",
      " [7] \"Jurkat\"                      \"THP1\"                       \n",
      " [9] \"THP1_LPS_4hr\"                \"GM12878\"                    \n",
      "[11] \"LNCAP\"                      \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "data <- read.table(\"/scratch/Users/geba9152/LIET-summer2024/correlation-erna-anaysis/41586_2021_3446_MOESM7_ESM.txt\", sep = \"\\t\", header = TRUE, stringsAsFactors = FALSE)\n",
    "\n",
    "# Print cell types\n",
    "\n",
    "## Options for us (present within DBNascent) - 1. K562, 2. Jurkat, 3. THP, 4. LNCAP, 5. GM12878 (only 3 samples, though)\n",
    "unique(data$CellType)\n",
    "\n",
    "# Plan: let's start with all K562 data we have already processed for LIET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adbe28f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['srr', 'sample_name', 'replicate', 'single_paired', 'rcomp', 'unusable',\n",
       "       'trim_read_depth', 'sample_qc_score', 'paper_id', 'sample_id',\n",
       "       'protocol', 'paper_name', 'organism', 'cell_type', 'sample_id.1',\n",
       "       'condition_type', 'treatment', 'conc_intens', 'start_time', 'end_time',\n",
       "       'duration', 'duration_unit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## I queryed across database so I can map SRRs I have already ran LIET on in K562s back to their respective papers\n",
    "# See query below\n",
    "all_srrs = pd.read_csv(\"/Users/geba9152/summer_2024_3prime/queries/all-human-PRO-GRO-query.txt\", sep = \"\\t\")\n",
    "all_srrs.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39164400",
   "metadata": {},
   "source": [
    "# First try correlation analysis on K562s that we have already run LIET on prelim genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d8e3b",
   "metadata": {},
   "source": [
    "### SQL Query for this analysis- querying everything & filtering for samples I want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641cb712",
   "metadata": {},
   "source": [
    "```\n",
    "mysql --host=socotra.int.colorado.edu --user=geba9152 --password=Fb38f0@%Ld9 dbnascent -e \"\\\n",
    "SELECT\n",
    "    sampleEquiv.srr,\n",
    "    samples.sample_name,\n",
    "    samples.replicate,\n",
    "    samples.single_paired,\n",
    "    samples.rcomp,\n",
    "    samples.unusable,\n",
    "    samples.trim_read_depth,\n",
    "    samples.sample_qc_score,\n",
    "    linkIDs.paper_id,\n",
    "    linkIDs.sample_id,\n",
    "    papers.protocol,\n",
    "    papers.paper_name,\n",
    "    organisms.organism,\n",
    "    genetics.cell_type,\n",
    "    conditionLink.sample_id,\n",
    "    conditions.condition_type,\n",
    "    conditions.treatment,\n",
    "    conditions.conc_intens,\n",
    "    conditions.start_time,\n",
    "    conditions.end_time,\n",
    "    conditions.duration,\n",
    "    conditions.duration_unit\n",
    "FROM\n",
    "    sampleEquiv\n",
    "    INNER JOIN samples ON samples.id = sampleEquiv.sample_id\n",
    "    INNER JOIN conditionLink ON samples.id = conditionLink.sample_id\n",
    "    INNER JOIN conditions ON conditionLink.condition_id = conditions.id\n",
    "    INNER JOIN linkIDs ON linkIDs.sample_id = samples.id\n",
    "    INNER JOIN papers ON papers.id = linkIDs.paper_id\n",
    "    INNER JOIN genetics ON genetics.id = linkIDs.genetic_id\n",
    "    INNER JOIN organisms ON genetics.organism_id = organisms.id\n",
    "WHERE\n",
    "    (papers.protocol = 'PRO-seq' OR papers.protocol = 'GRO-seq')\n",
    "    AND organisms.organism = 'H. sapiens'\n",
    "ORDER BY\n",
    "    genetics.cell_type;\" > /Users/geba9152/summer_2024_3prime/queries/all-human-PRO-GRO-query.txt```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4799c2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_name</th>\n",
       "      <th>paper_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>SRR12083665</td>\n",
       "      <td>Blumberg2021characterizing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>SRR8137173</td>\n",
       "      <td>Wang2019identification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>SRR4454568</td>\n",
       "      <td>Vihervaara2017transcriptional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>SRR4454567</td>\n",
       "      <td>Vihervaara2017transcriptional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>SRR11793826</td>\n",
       "      <td>Judd2020unpublished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>SRR11793825</td>\n",
       "      <td>Judd2020unpublished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>SRR12083664</td>\n",
       "      <td>Blumberg2021characterizing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>SRZ1554311</td>\n",
       "      <td>Core2014analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>SRZ1554311</td>\n",
       "      <td>Core2014analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>SRR5364303</td>\n",
       "      <td>Dukler2017nascent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>SRR5364304</td>\n",
       "      <td>Dukler2017nascent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>SRR8669163</td>\n",
       "      <td>Vihervaara2021stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>SRR8669162</td>\n",
       "      <td>Vihervaara2021stress</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample_name                     paper_name\n",
       "1112  SRR12083665     Blumberg2021characterizing\n",
       "1113   SRR8137173         Wang2019identification\n",
       "1116   SRR4454568  Vihervaara2017transcriptional\n",
       "1117   SRR4454567  Vihervaara2017transcriptional\n",
       "1121  SRR11793826            Judd2020unpublished\n",
       "1122  SRR11793825            Judd2020unpublished\n",
       "1127  SRR12083664     Blumberg2021characterizing\n",
       "1129   SRZ1554311               Core2014analysis\n",
       "1130   SRZ1554311               Core2014analysis\n",
       "1131   SRR5364303              Dukler2017nascent\n",
       "1132   SRR5364304              Dukler2017nascent\n",
       "1143   SRR8669163           Vihervaara2021stress\n",
       "1144   SRR8669162           Vihervaara2021stress"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K562 SRRs I ran LIET on \n",
    "k562s = [\"SRR11793825\", \"SRR11793826\", \"SRR12083664\", \"SRR12083665\",\n",
    "         \"SRR4454567\", \"SRR4454568\", \"SRR5364303\", \"SRR5364304\", \n",
    "         \"SRR8137173\", \"SRR8669162\", \"SRR8669163\", \"SRZ1554311\"]\n",
    "\n",
    "# filter to get paper names\n",
    "all_srrs = all_srrs[['sample_name','paper_name']]\n",
    "all_srrs[all_srrs['sample_name'].isin(k562s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2736895c",
   "metadata": {},
   "source": [
    "**K562 papers & associated SRRs (that LIET has been run on so far)^^:**\n",
    "\n",
    "Now I am going to make a `bash` script to pull TFit and Dreg calls for each paper\n",
    "\n",
    "I think I will do mu merge calls **1st.** by paper and **2nd.** by condition. \n",
    "\n",
    "All of these samples have no treatment, so we can do mu merge by papers only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf37d7a9",
   "metadata": {},
   "source": [
    "### Make mumerge input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b331898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dreg\n",
    "# dreg_tfit = 'dreg'\n",
    "# prefix = '.sorted.dREG.full.covfiltered'\n",
    "# input_file = '/scratch/Users/geba9152/LIET-summer2024/correlation-erna-anaysis/paper_names.txt'\n",
    "\n",
    "\n",
    "# tfit\n",
    "dreg_tfit = 'tfit'\n",
    "prefix = '.sorted_split_bidir_cov_filtered'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a76b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mumerge_file(dreg_tfit, prefix, input_file):\n",
    "    # Read the input file\n",
    "    df = pd.read_csv(input_file, sep='\\t')\n",
    "    \n",
    "    # Create a dictionary to keep track of sample numbers for each paper\n",
    "    sample_counts = {}\n",
    "\n",
    "    # Create a list to store the output lines\n",
    "    output_lines = []\n",
    "\n",
    "    # Loop through the dataframe and generate the output lines\n",
    "    for index, row in df.iterrows():\n",
    "        srr = row['srr']\n",
    "        paper = row['paper']\n",
    "\n",
    "        if paper not in sample_counts:\n",
    "            sample_counts[paper] = 1\n",
    "        else:\n",
    "            sample_counts[paper] += 1\n",
    "\n",
    "        sample_id = f'sample{sample_counts[paper]}'\n",
    "        file_path = f'/scratch/Users/geba9152/LIET-summer2024/correlation-erna-anaysis/{dreg_tfit}/{srr}{prefix}.bed'\n",
    "        group = paper.replace(' ', '_')  # Replace spaces with underscores to avoid issues with file names\n",
    "        output_line = f'{file_path}\\t{sample_id}\\t{group}'\n",
    "        output_lines.append(output_line)\n",
    "\n",
    "    # Write the output lines to a file\n",
    "    output_file = f'/scratch/Users/geba9152/LIET-summer2024/correlation-erna-anaysis/mumerge-{dreg_tfit}-input.txt'\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write('file\\tsampid\\tgroup\\n')\n",
    "        for line in output_lines:\n",
    "            f.write(line + '\\n')\n",
    "\n",
    "make_mumerge_file(dreg_tfit, prefix, input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8074b2f9",
   "metadata": {},
   "source": [
    "### Make bedfiles -1kb of PAS to mT + 2 sigma\n",
    "- I will intersect this with the mumerged bidir file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f0a877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "srrs = [\"SRR11793825\", \"SRR11793826\", \"SRR12083664\", \"SRR12083665\",\n",
    "         \"SRR4454567\", \"SRR4454568\", \"SRR5364303\", \"SRR5364304\", \n",
    "         \"SRR8137173\", \"SRR8669162\", \"SRR8669163\", \"SRZ1554311\"]\n",
    "\n",
    "filepath = '/scratch/Users/geba9152/LIET-summer2024/k562-batch/results/tight-sT/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10e1fd6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 5, saw 10\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m         df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msrr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.liet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 10\u001b[0m make_intersect_bed(srrs, filepath)\n",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m, in \u001b[0;36mmake_intersect_bed\u001b[0;34m(srrs, filepath)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_intersect_bed\u001b[39m(srrs, filepath):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m srr \u001b[38;5;129;01min\u001b[39;00m srrs: \n\u001b[0;32m----> 5\u001b[0m         df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msrr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.liet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/miniconda3/envs/rpy2_env/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/rpy2_env/lib/python3.11/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m~/miniconda3/envs/rpy2_env/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m         nrows\n\u001b[1;32m   1925\u001b[0m     )\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/rpy2_env/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 5, saw 10\n"
     ]
    }
   ],
   "source": [
    "def make_intersect_bed(srrs, filepath):\n",
    "    \n",
    "    for srr in srrs: \n",
    "    \n",
    "        lietfile = f\"{filepath}{srr}.liet\"\n",
    "        \n",
    "#         # get list of files for each type\n",
    "#     lietfiles = glob.glob(lietpath)\n",
    "# #     logfiles = glob.glob(logpath)\n",
    "# #     configfiles = glob.glob(configpath)\n",
    "\n",
    "#     # process each group of files \n",
    "# #     for configfile, lietfile, logfile in zip(configfiles, lietfiles, logfiles):\n",
    "#     for lietfile in lietfiles:\n",
    "#         celltype = os.path.basename(lietfile).split('.')[0]  # extract celltype from filename\n",
    "       \n",
    "#         # call fitparse function to get model params\n",
    "#         fit_parser = FitParse(lietfile)\n",
    "        \n",
    "#         data = {\n",
    "#             \"Gene\": fit_parser.genes,\n",
    "#             \"mL\": fit_parser.mL,\n",
    "#             \"mL_std\": fit_parser.mL_std,\n",
    "#             \"sL\": fit_parser.sL,\n",
    "#             \"sL_std\": fit_parser.sL_std,\n",
    "#             \"tI\": fit_parser.tI,\n",
    "#             \"tI_std\": fit_parser.tI_std,\n",
    "#             \"mT\": fit_parser.mT,\n",
    "#             \"mT_std\": fit_parser.mT_std,\n",
    "#             \"sT\": fit_parser.sT,\n",
    "#             \"sT_std\": fit_parser.sT_std,\n",
    "#             \"w\": fit_parser.w,\n",
    "#             \"w_std\": fit_parser.w_std,\n",
    "#             \"mL_a\": fit_parser.mL_a,\n",
    "#             \"mL_a_std\": fit_parser.mL_a_std,\n",
    "#             \"sL_a\": fit_parser.sL_a,\n",
    "#             \"sL_a_std\": fit_parser.sL_a_std,\n",
    "#             \"tI_a\": fit_parser.tI_a,\n",
    "#             \"tI_a_std\": fit_parser.tI_a_std,\n",
    "#             \"w_a\": fit_parser.w_a,\n",
    "#             \"w_a_std\": fit_parser.w_a_std,\n",
    "#         }\n",
    "        \n",
    "#         return df\n",
    "    \n",
    "\n",
    "make_intersect_bed(srrs, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0250423d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rpy2_env",
   "language": "python",
   "name": "rpy2_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
